"""
Multi-Stage Query Pipeline Service

Implements 6-stage query processing for maximum accuracy:
1. Intent Analysis & Schema Linking
2. Query Skeleton Generation
3. SQL Generation with RAG
4. Syntax Validation
5. Dry Run Execution
6. Semantic Validation

This pipeline ensures queries are validated before execution,
reducing errors and improving accuracy.
"""

import logging
from typing import Dict, Any, Optional, List
import json
import sqlparse

from ..services.ollama_service import ollama_service
from ..services.query_pattern_service import query_pattern_service
from ..services.duckdb_service import duckdb_service
from ..agents.sql_generation_agent_v2 import sql_generation_agent
from ..agents.intent_classifier_agent import intent_classifier

logger = logging.getLogger(__name__)


class QueryPipelineService:
    """
    Multi-stage query processing pipeline for high-accuracy SQL generation.
    """
    
    def __init__(self):
        self.max_validation_attempts = 2
    
    async def process_query(
        self,
        question: str,
        schema: Dict[str, Any],
        dataset_id: int,
        df = None
    ) -> Dict[str, Any]:
        """
        Process query through 6-stage pipeline.
        
        Args:
            question: Natural language question
            schema: Dataset schema
            dataset_id: Dataset ID
            df: Optional DataFrame for dry-run
            
        Returns:
            Pipeline result with validated SQL
        """
        try:
            logger.info(f"üîÑ Starting 6-stage pipeline for: {question[:50]}...")
            
            # Stage 1: Intent Analysis & Schema Linking
            stage1_result = await self._stage1_intent_analysis(question, schema)
            if not stage1_result['success']:
                return stage1_result
            
            # Stage 2: Query Skeleton Generation
            stage2_result = await self._stage2_query_skeleton(
                question, schema, stage1_result['intent_data']
            )
            if not stage2_result['success']:
                return stage2_result
            
            # Stage 3: SQL Generation with RAG
            stage3_result = await self._stage3_sql_generation(
                question, schema, stage1_result['intent_data'], 
                stage2_result['skeleton'], dataset_id
            )
            if not stage3_result['success']:
                return stage3_result
            
            # Stage 4: Syntax Validation
            stage4_result = await self._stage4_syntax_validation(
                stage3_result['sql'], question, schema
            )
            if not stage4_result['valid']:
                # Try to fix syntax errors
                stage3_result = await self._stage3_sql_generation(
                    question, schema, stage1_result['intent_data'],
                    stage2_result['skeleton'], dataset_id,
                    error_context=stage4_result['error']
                )
            
            # Stage 5: Dry Run Execution
            stage5_result = await self._stage5_dry_run(
                stage3_result['sql'], dataset_id
            )
            if not stage5_result['success']:
                return {
                    'success': False,
                    'error': 'Dry run failed',
                    'details': stage5_result
                }
            
            # Stage 6: Semantic Validation
            stage6_result = await self._stage6_semantic_validation(
                stage3_result['sql'], stage5_result['preview'], question
            )
            
            # Build final result
            return {
                'success': True,
                'sql': stage3_result['sql'],
                'intent': stage1_result['intent_data']['intent'],
                'skeleton': stage2_result['skeleton'],
                'validation': {
                    'syntax_valid': stage4_result['valid'],
                    'dry_run_success': stage5_result['success'],
                    'semantic_score': stage6_result['score']
                },
                'pipeline_stages': {
                    'stage1': 'Intent Analysis ‚úì',
                    'stage2': 'Query Skeleton ‚úì',
                    'stage3': 'SQL Generation ‚úì',
                    'stage4': 'Syntax Validation ‚úì',
                    'stage5': 'Dry Run ‚úì',
                    'stage6': 'Semantic Validation ‚úì'
                }
            }
            
        except Exception as e:
            logger.error(f"Pipeline error: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    async def _stage1_intent_analysis(
        self, question: str, schema: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Stage 1: Analyze intent and link to schema"""
        try:
            logger.info("üìä Stage 1: Intent Analysis & Schema Linking")
            
            # Classify intent
            intent_result = intent_classifier.classify(question, schema)
            
            # Extract entities from question
            entities = self._extract_entities(question, schema)
            
            return {
                'success': True,
                'intent_data': {
                    'intent': intent_result.get('intent', 'DESCRIPTIVE'),
                    'confidence': intent_result.get('confidence', 0.5),
                    'entities': entities,
                    'interpretation': intent_result.get('interpretation', '')
                }
            }
        except Exception as e:
            logger.error(f"Stage 1 error: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _stage2_query_skeleton(
        self, question: str, schema: Dict[str, Any], intent_data: Dict
    ) -> Dict[str, Any]:
        """Stage 2: Generate high-level query structure"""
        try:
            logger.info("üèóÔ∏è  Stage 2: Query Skeleton Generation")
            
            prompt = f"""Generate a high-level SQL query skeleton (structure only, no actual SQL).

Question: {question}
Intent: {intent_data['intent']}
Entities: {', '.join(intent_data['entities'])}

Return JSON with:
{{
  "select_targets": ["column1", "column2"],
  "from_tables": ["table_name"],
  "where_filters": ["condition1", "condition2"],
  "group_by": ["column"],
  "order_by": ["column DESC"],
  "limit": 10
}}"""
            
            response = ollama_service.generate_response(
                prompt=prompt,
                json_mode=True,
                temperature=0.2,
                task_type='sql_generation'
            )
            
            skeleton = json.loads(response)
            
            return {
                'success': True,
                'skeleton': skeleton
            }
        except Exception as e:
            logger.error(f"Stage 2 error: {e}")
            return {
                'success': True,  # Non-critical, continue without skeleton
                'skeleton': {}
            }
    
    async def _stage3_sql_generation(
        self,
        question: str,
        schema: Dict[str, Any],
        intent_data: Dict,
        skeleton: Dict,
        dataset_id: int,
        error_context: Optional[str] = None
    ) -> Dict[str, Any]:
        """Stage 3: Generate SQL with RAG examples"""
        try:
            logger.info("üíª Stage 3: SQL Generation with RAG")
            
            # Get similar queries for few-shot learning
            similar_queries = await query_pattern_service.find_similar_queries(
                question, dataset_id, top_k=3
            )
            
            # Build query analysis
            query_analysis = {
                'intent': intent_data['intent'],
                'entities': intent_data['entities'],
                'skeleton': skeleton
            }
            
            # Add error context if retrying
            if error_context:
                query_analysis['previous_error'] = error_context
            
            # Generate SQL
            sql_result = await sql_generation_agent.generate_sql(
                question, schema, query_analysis, similar_queries
            )
            
            return {
                'success': sql_result['success'],
                'sql': sql_result.get('sql', ''),
                'reasoning': sql_result.get('reasoning', '')
            }
        except Exception as e:
            logger.error(f"Stage 3 error: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _stage4_syntax_validation(
        self, sql: str, question: str, schema: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Stage 4: Validate SQL syntax"""
        try:
            logger.info("‚úÖ Stage 4: Syntax Validation")
            
            # Parse SQL
            try:
                parsed = sqlparse.parse(sql)
                if not parsed:
                    return {
                        'valid': False,
                        'error': 'Failed to parse SQL'
                    }
                
                # Check for common issues
                sql_lower = sql.lower()
                
                # Check table name is 'data'
                if 'from' in sql_lower:
                    if 'from data' not in sql_lower and 'from "data"' not in sql_lower:
                        return {
                            'valid': False,
                            'error': 'Table name must be "data"'
                        }
                
                # Check for SELECT
                if not sql_lower.strip().startswith('select'):
                    return {
                        'valid': False,
                        'error': 'Query must start with SELECT'
                    }
                
                return {'valid': True}
                
            except Exception as e:
                return {
                    'valid': False,
                    'error': f'Syntax error: {str(e)}'
                }
                
        except Exception as e:
            logger.error(f"Stage 4 error: {e}")
            return {'valid': True}  # Don't block on validation errors
    
    async def _stage5_dry_run(
        self, sql: str, dataset_id: int
    ) -> Dict[str, Any]:
        """Stage 5: Execute with LIMIT 1 to catch runtime errors"""
        try:
            logger.info("üß™ Stage 5: Dry Run Execution")
            
            # Add LIMIT 1 if not present
            dry_run_sql = sql
            if 'limit' not in sql.lower():
                dry_run_sql = f"{sql.rstrip(';')} LIMIT 1"
            else:
                # Replace existing LIMIT with LIMIT 1
                import re
                dry_run_sql = re.sub(r'LIMIT\s+\d+', 'LIMIT 1', sql, flags=re.IGNORECASE)
            
            # Execute dry run
            result = duckdb_service.execute_query(dataset_id, dry_run_sql)
            
            if result['success']:
                return {
                    'success': True,
                    'preview': result['data']
                }
            else:
                return {
                    'success': False,
                    'error': result.get('error', 'Unknown error')
                }
                
        except Exception as e:
            logger.error(f"Stage 5 error: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    async def _stage6_semantic_validation(
        self, sql: str, preview: List[Dict], question: str
    ) -> Dict[str, Any]:
        """Stage 6: Validate query makes semantic sense"""
        try:
            logger.info("üîç Stage 6: Semantic Validation")
            
            # Check if preview has data
            if not preview or len(preview) == 0:
                return {
                    'score': 0.5,
                    'warning': 'Query returned no results - might indicate bad filter'
                }
            
            # Check for negative values in revenue/sales columns
            for row in preview:
                for key, value in row.items():
                    if any(term in key.lower() for term in ['revenue', 'sales', 'price', 'amount']):
                        if isinstance(value, (int, float)) and value < 0:
                            return {
                                'score': 0.3,
                                'warning': f'Negative value in {key}: {value}'
                            }
            
            # All checks passed
            return {
                'score': 1.0,
                'status': 'Valid'
            }
            
        except Exception as e:
            logger.error(f"Stage 6 error: {e}")
            return {'score': 0.8}  # Assume valid if validation fails
    
    def _extract_entities(self, question: str, schema: Dict[str, Any]) -> List[str]:
        """Extract entities mentioned in question"""
        entities = []
        question_lower = question.lower()
        
        # Extract column names mentioned
        for col in schema.get('columns', []):
            col_name = col.get('name', '').lower()
            if col_name in question_lower:
                entities.append(col_name)
        
        # Extract common business terms
        business_terms = ['revenue', 'sales', 'profit', 'customer', 'product', 'order']
        for term in business_terms:
            if term in question_lower:
                entities.append(term)
        
        return list(set(entities))


# Singleton instance
query_pipeline_service = QueryPipelineService()
