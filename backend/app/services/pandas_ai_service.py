import pandas as pd
import logging
from typing import Dict, Any, Optional
import base64
from pandasai import SmartDataframe
from pandasai.llm.base import LLM
# from pandasai.core.prompts.base import BasePrompt

from ..config import settings
from ..services.ollama_service import ollama_service

logger = logging.getLogger(__name__)

class PandasAIAnthropicLLM(LLM):
    """
    Custom Anthropic LLM for PandasAI using appropriate models.
    """
    def __init__(self, api_key: str, model: str, **kwargs):
        super().__init__(**kwargs)
        self.api_key = api_key
        self.model = model
        self.client = None
        try:
             import anthropic
             self.client = anthropic.Anthropic(api_key=api_key)
        except ImportError:
             raise ImportError("anthropic package not installed")

    def type(self) -> str:
        return "anthropic"

    def call(self, instruction: Any, context: Any = None) -> str:
        if hasattr(instruction, 'to_string'):
            prompt_text = instruction.to_string()
        else:
            prompt_text = str(instruction)
            
        try:
             message = self.client.messages.create(
                 model=self.model,
                 max_tokens=4096,
                 temperature=0.1,
                 messages=[{"role": "user", "content": prompt_text}]
             )
             return message.content[0].text
        except Exception as e:
             logger.error(f"Anthropic LLM Error: {e}")
             raise e

class PandasAIOllamaLLM(LLM):
    """
    Custom Ollama LLM for PandasAI.
    """
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        from ..config import settings
        import ollama
        self.host = settings.OLLAMA_HOST
        self.model = settings.OLLAMA_MODEL
        self.client = ollama.Client(host=self.host)

    def type(self) -> str:
        return "ollama"

    def call(self, instruction: Any, context: Any = None) -> str:
        if hasattr(instruction, 'to_string'):
            prompt_text = instruction.to_string()
        else:
            prompt_text = str(instruction)
            
        try:
            response = self.client.generate(model=self.model, prompt=prompt_text)
            return response['response']
        except Exception as e:
            logger.error(f"Ollama LLM Error: {e}")
            raise e

class PandasAIService:
    """
    Service wrapper for PandasAI library.
    Provides natural language analysis and visualization capabilities "exactly like pandas-ai".
    """
    
    def __init__(self):
        self.llm = self._configure_llm()
    
    def _configure_llm(self):
        """Configure the LLM for PandasAI"""
        if settings.USE_ANTHROPIC and settings.ANTHROPIC_API_KEY:
             logger.info(f"Using Custom Anthropic LLM for PandasAI: {settings.ANTHROPIC_MODEL}")
             return PandasAIAnthropicLLM(
                 api_key=settings.ANTHROPIC_API_KEY,
                 model=settings.ANTHROPIC_MODEL
             )
        
        # Default fallback to Ollama (even if it might fail if not running)
        return PandasAIOllamaLLM()

    def analyze(self, df: pd.DataFrame, query: str) -> Dict[str, Any]:
        """
        Analyze dataframe using PandasAI.
        
        Args:
            df: Pandas DataFrame
            query: User's natural language query
            
        Returns:
            Dict containing:
            - answer: Text response
            - plot_image: Base64 encoded image (if generated)
            - code: The code generated by PandasAI
        """
        try:
            # Configure SmartDataframe
            sdf = SmartDataframe(
                df, 
                config={
                    "llm": self.llm,
                    "save_charts": True,
                    "save_charts_path": settings.UPLOAD_DIR,
                    "enable_cache": False, # Disable cache to prevent stale results during dev
                    "custom_whitelisted_dependencies": ["matplotlib", "seaborn", "plotly", "scipy", "numpy"],
                    "verbose": True,
                    # "response_parser": ... # Let default parser handle it initially
                }
            )
            
            # Execute chat
            # Prepend robust instructions to prevent hallucinations about "execute_sql_query"
            enhanced_query = f"{query}\n\nIMPORTANT: You must analyze the dataframe 'df' using standard pandas python code. Do NOT try to use SQL. Do NOT call 'execute_sql_query'. Use simple print() or result assignment."
            response = sdf.chat(enhanced_query)
            logger.info(f"PandasAI Execution Result Type: {type(response)}")
            logger.info(f"PandasAI Execution Result: {response}")
            
            plot_image = None
            answer = ""
            
            # Clean response if it's a string
            if isinstance(response, str):
                response = response.strip()
                # Check if it looks like a dict string
                if response.startswith("{") and response.endswith("}"):
                    try:
                        import ast
                        response_dict = ast.literal_eval(response)
                        if isinstance(response_dict, dict) and 'value' in response_dict:
                            response = response_dict['value']
                    except Exception:
                        pass

            # Handle response specifically looking for image paths
            is_image_path = False
            image_path = ""
            
            # Check for plot file
            if isinstance(response, str):
                if response.lower().endswith('.png') or response.lower().endswith('.jpg') or response.lower().endswith('.jpeg'):
                    is_image_path = True
                    image_path = response
                elif isinstance(response, dict) and response.get('type') == 'plot':
                    is_image_path = True
                    image_path = response.get('value')
            
            # Additional check: Look at executed code for savefig
            if not is_image_path and hasattr(sdf, 'last_code_executed') and sdf.last_code_executed:
                import re
                # Look for .savefig('filename') or .savefig("filename")
                match = re.search(r"savefig\(['\"]([^'\"]+)['\"]\)", sdf.last_code_executed)
                if match:
                    potential_path = match.group(1)
                    logger.info(f"Found potential chart path in code: {potential_path}")
                    is_image_path = True
                    image_path = potential_path

            # Check for plot file
            if is_image_path:
                 try:
                    import os
                    # Clean path
                    if image_path.startswith("'") or image_path.startswith('"'):
                        image_path = image_path.strip("'\"")
                        
                    logger.info(f"PandasAI returned path: {image_path}")
                    logger.info(f"Current CWD: {os.getcwd()}")
                    
                    file_path = image_path
                    if not os.path.exists(file_path):
                        # Try relative to CWD
                        file_path = os.path.join(os.getcwd(), image_path)
                        logger.info(f"Tried absolute path: {file_path}")
                    
                    if not os.path.exists(file_path):
                        # Fallback: check exports/charts explicitly if response was just filename
                        if "exports/charts" not in image_path:
                             fallback = os.path.join(os.getcwd(), "exports/charts", os.path.basename(image_path))
                             if os.path.exists(fallback):
                                 file_path = fallback
                                 logger.info(f"Found at fallback: {file_path}")
                    
                    if not os.path.exists(file_path):
                        logger.error(f"Chart file REALLY not found at {image_path} or {file_path}")
                        # Check recursively in current dir for any png with that name
                        filename = os.path.basename(image_path)
                        for root, dirs, files in os.walk(os.getcwd()):
                            if filename in files:
                                file_path = os.path.join(root, filename)
                                logger.info(f"Found via walk: {file_path}")
                                break
                    
                    if not os.path.exists(file_path):
                         answer = f"Chart generated at {image_path} but could not be loaded."
                    else:
                        with open(file_path, "rb") as image_file:
                            plot_image = base64.b64encode(image_file.read()).decode('utf-8')
                        answer = "I have generated the chart for you."
                 except Exception as e:
                    logger.error(f"Failed to read chart file: {e}")
                    answer = "Generated chart but failed to load it."
            
            elif isinstance(response, pd.DataFrame):
                answer = response.to_markdown()
                
            elif isinstance(response, SmartDataframe):
                 # Sometimes returns itself?
                 answer = "Operation completed."
            
            else:
                answer = str(response)

            return {
                "success": True,
                "answer": answer,
                "plot_image": plot_image,
                "code": sdf.last_code_executed, # Verify if this property exists in v3
                "raw_response": str(response)
            }
            
        except Exception as e:
            logger.error(f"PandasAI Analysis Error: {e}", exc_info=True)
            try:
                 logger.error(f"Last Code Executed:\n{sdf.last_code_executed}")
            except:
                 pass
            return {
                "success": False,
                "error": str(e)
            }

pandas_ai_service = PandasAIService()
