
import sys
import os
import asyncio
import pandas as pd

# Add backend to path
sys.path.append(os.path.join(os.path.dirname(__file__), '../backend'))

# We still mock DB session/Data loading because we don't have a real DB path setup easily here,
# but we will NOT mock the Agents or Services (Validation, Intent, Analysis).
from unittest.mock import MagicMock, AsyncMock

# Mock dependencies that require a real running API server context or DB file
# But keep the Logic components real.

# Mock Database Session
mock_db = MagicMock()

async def test_integration_real():
    print("üöÄ Starting Real Integration Test (No Agent Mocks)")
    
    # Import service 
    from app.services.analytics_service_v4 import analytics_service_v4
    from app.services.duckdb_service import duckdb_service
    # Ensure config is loaded
    from app.config import settings
    print(f"üîß Config: Use Ollama={settings.USE_OLLAMA}, Model={settings.OLLAMA_MODEL}, EmbModel={settings.OLLAMA_EMBEDDING_MODEL}")

    # 1. Setup Data
    dataset_id = 999
    df = pd.DataFrame({
        'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
        'y': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],
        'category': ['A', 'A', 'B', 'B', 'C', 'C', 'A', 'B', 'C', 'A']
    })
    
    # Register data in DuckDB
    try:
        conn = duckdb_service.get_connection(dataset_id)
        # Check if table exists, if so drop it
        conn.execute("DROP TABLE IF EXISTS data")
        conn.register('data', df)
    except Exception as e:
        print(f"‚ö†Ô∏è DuckDB setup warning: {e}")
        
    
    try:
        # 3. Test Routing (Asking for Correlation)
        # This will actually call Ollama for Validation, Intent, and Code Gen
        question = "Calculate the correlation between x and y and plot it"
        print(f"\nTesting Question: '{question}'")
        
        # We need to ensure the event loop exists for async calls
        result = await analytics_service_v4.analyze_query(question, dataset_id, mock_db)
        
        # 4. Assertions
        print(f"\n--- Result ---")
        print(f"Success: {result.get('success')}")
        print(f"Metadata Agent: {result.get('metadata', {}).get('agent')}")
        
        if not result.get('success'):
             print(f"‚ùå Error: {result.get('error')}")
             # Print trace if valid
             return

        # Verify Routing
        if result.get('metadata', {}).get('agent') == 'python_analyst':
            print("‚úÖ Correctly routed to Python Analyst Agent")
        else:
            print(f"‚ùå Failed to route to Python Agent (Got: {result.get('metadata', {}).get('agent')})")
            
        # Verify Visualization format
        viz = result.get('visualization')
        if viz and len(viz) > 0 and viz[0]['chart_type'] == 'plotly_json':
             print("‚úÖ Visualization format is correct (plotly_json)")
        else:
             print(f"‚ùå Visualization format incorrect: {viz}")
             
        # Verify Insights (generated by LLM)
        insights = result.get('insights')
        if insights and len(insights) > 10:
             print("‚úÖ Insights generated")
        else:
             print("‚ö†Ô∏è Insights empty or short")

    except Exception as e:
        print(f"‚ùå Exception during test: {e}")
        import traceback
        traceback.print_exc()
             
    finally:
        duckdb_service.close_connection(dataset_id)

if __name__ == "__main__":
    asyncio.run(test_integration_real())
